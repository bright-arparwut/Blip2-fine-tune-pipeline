{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1111676,"sourceType":"datasetVersion","datasetId":623289}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade --q transformers lightning datasets bitsandbytes gspread oauth2client wandb","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:05:39.631425Z","iopub.execute_input":"2024-05-30T13:05:39.631825Z","iopub.status.idle":"2024-05-30T13:06:20.107571Z","shell.execute_reply.started":"2024-05-30T13:05:39.631791Z","shell.execute_reply":"2024-05-30T13:06:20.105851Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport lightning as pl\n\nimport transformers\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BitsAndBytesConfig\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\n","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:39:27.831179Z","iopub.execute_input":"2024-05-30T13:39:27.831707Z","iopub.status.idle":"2024-05-30T13:39:27.838956Z","shell.execute_reply.started":"2024-05-30T13:39:27.831670Z","shell.execute_reply":"2024-05-30T13:39:27.837869Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Data Prep\n* Prep data.csv\n* Define the DataModule\n* Define the LightningModule\n","metadata":{}},{"cell_type":"code","source":"PATH_DIR = \"/kaggle/input/flickr8k\"\nIMAGE_FOLDER_DIR = \"/kaggle/input/flickr8k/Images\"","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:06:41.739812Z","iopub.execute_input":"2024-05-30T13:06:41.740482Z","iopub.status.idle":"2024-05-30T13:06:41.746157Z","shell.execute_reply.started":"2024-05-30T13:06:41.740443Z","shell.execute_reply":"2024-05-30T13:06:41.744750Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/flickr8k/captions.txt')\ndata.rename(columns={\"image\":\"image_path\",\"caption\":\"text\"},inplace=True)\ndata","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:06:43.592746Z","iopub.execute_input":"2024-05-30T13:06:43.593154Z","iopub.status.idle":"2024-05-30T13:06:43.762852Z","shell.execute_reply.started":"2024-05-30T13:06:43.593118Z","shell.execute_reply":"2024-05-30T13:06:43.761905Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                      image_path  \\\n0      1000268201_693b08cb0e.jpg   \n1      1000268201_693b08cb0e.jpg   \n2      1000268201_693b08cb0e.jpg   \n3      1000268201_693b08cb0e.jpg   \n4      1000268201_693b08cb0e.jpg   \n...                          ...   \n40450   997722733_0cb5439472.jpg   \n40451   997722733_0cb5439472.jpg   \n40452   997722733_0cb5439472.jpg   \n40453   997722733_0cb5439472.jpg   \n40454   997722733_0cb5439472.jpg   \n\n                                                    text  \n0      A child in a pink dress is climbing up a set o...  \n1                  A girl going into a wooden building .  \n2       A little girl climbing into a wooden playhouse .  \n3      A little girl climbing the stairs to her playh...  \n4      A little girl in a pink dress going into a woo...  \n...                                                  ...  \n40450           A man in a pink shirt climbs a rock face  \n40451           A man is rock climbing high in the air .  \n40452  A person in a red shirt climbing up a rock fac...  \n40453                    A rock climber in a red shirt .  \n40454  A rock climber practices on a rock climbing wa...  \n\n[40455 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A child in a pink dress is climbing up a set o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A girl going into a wooden building .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing into a wooden playhouse .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing the stairs to her playh...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl in a pink dress going into a woo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>40450</th>\n      <td>997722733_0cb5439472.jpg</td>\n      <td>A man in a pink shirt climbs a rock face</td>\n    </tr>\n    <tr>\n      <th>40451</th>\n      <td>997722733_0cb5439472.jpg</td>\n      <td>A man is rock climbing high in the air .</td>\n    </tr>\n    <tr>\n      <th>40452</th>\n      <td>997722733_0cb5439472.jpg</td>\n      <td>A person in a red shirt climbing up a rock fac...</td>\n    </tr>\n    <tr>\n      <th>40453</th>\n      <td>997722733_0cb5439472.jpg</td>\n      <td>A rock climber in a red shirt .</td>\n    </tr>\n    <tr>\n      <th>40454</th>\n      <td>997722733_0cb5439472.jpg</td>\n      <td>A rock climber practices on a rock climbing wa...</td>\n    </tr>\n  </tbody>\n</table>\n<p>40455 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df, val_df = train_test_split(data,\n                                   test_size=.02,\n                                   shuffle=True,\n                                   random_state=42,)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:06:47.137171Z","iopub.execute_input":"2024-05-30T13:06:47.137796Z","iopub.status.idle":"2024-05-30T13:06:47.157862Z","shell.execute_reply.started":"2024-05-30T13:06:47.137763Z","shell.execute_reply":"2024-05-30T13:06:47.155686Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df.reset_index(inplace=True,\n                     drop=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:06:57.258857Z","iopub.execute_input":"2024-05-30T13:06:57.259660Z","iopub.status.idle":"2024-05-30T13:06:57.276055Z","shell.execute_reply.started":"2024-05-30T13:06:57.259616Z","shell.execute_reply":"2024-05-30T13:06:57.274937Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                      image_path  \\\n0      3630641436_8f9ac5b9b2.jpg   \n1      3494394662_3edfd4a34c.jpg   \n2      3435648640_b2f68efb78.jpg   \n3      2847615962_c330bded6e.jpg   \n4       439916996_1ddb9dc8e7.jpg   \n...                          ...   \n39640  2220175999_081aa9cce8.jpg   \n39641  2555622234_3e531e4014.jpg   \n39642   525887861_4cc7a1beca.jpg   \n39643  1204996216_71d7519d9a.jpg   \n39644  2862931640_2501bd36c5.jpg   \n\n                                                    text  \n0      Three dogs rush to chase a ball thrown into th...  \n1      A man with a red collar and gray beard looks a...  \n2      A black dog and a brindle dog wrestle in the d...  \n3      A spotted dog rolling over on a pad placed on ...  \n4      A brown dog persues a Frisbee across the grass...  \n...                                                  ...  \n39640                     Two big dogs wade in the ocean  \n39641  A wet German Shepherd runs along the waves on ...  \n39642                   Little girl in pink skateboard .  \n39643               A boy lays on a picnic table bench .  \n39644  A group of young people pose for a group photo...  \n\n[39645 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3630641436_8f9ac5b9b2.jpg</td>\n      <td>Three dogs rush to chase a ball thrown into th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3494394662_3edfd4a34c.jpg</td>\n      <td>A man with a red collar and gray beard looks a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3435648640_b2f68efb78.jpg</td>\n      <td>A black dog and a brindle dog wrestle in the d...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2847615962_c330bded6e.jpg</td>\n      <td>A spotted dog rolling over on a pad placed on ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>439916996_1ddb9dc8e7.jpg</td>\n      <td>A brown dog persues a Frisbee across the grass...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39640</th>\n      <td>2220175999_081aa9cce8.jpg</td>\n      <td>Two big dogs wade in the ocean</td>\n    </tr>\n    <tr>\n      <th>39641</th>\n      <td>2555622234_3e531e4014.jpg</td>\n      <td>A wet German Shepherd runs along the waves on ...</td>\n    </tr>\n    <tr>\n      <th>39642</th>\n      <td>525887861_4cc7a1beca.jpg</td>\n      <td>Little girl in pink skateboard .</td>\n    </tr>\n    <tr>\n      <th>39643</th>\n      <td>1204996216_71d7519d9a.jpg</td>\n      <td>A boy lays on a picnic table bench .</td>\n    </tr>\n    <tr>\n      <th>39644</th>\n      <td>2862931640_2501bd36c5.jpg</td>\n      <td>A group of young people pose for a group photo...</td>\n    </tr>\n  </tbody>\n</table>\n<p>39645 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"val_df.reset_index(inplace=True,\n                   drop=True)\nval_df","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:06:59.765396Z","iopub.execute_input":"2024-05-30T13:06:59.766386Z","iopub.status.idle":"2024-05-30T13:06:59.779020Z","shell.execute_reply.started":"2024-05-30T13:06:59.766343Z","shell.execute_reply":"2024-05-30T13:06:59.777937Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                    image_path  \\\n0    2973269132_252bfd0160.jpg   \n1     270263570_3160f360d3.jpg   \n2    2053006423_6adf69ca67.jpg   \n3     512101751_05a6d93e19.jpg   \n4    3156406419_38fbd52007.jpg   \n..                         ...   \n805  1392272228_cf104086e6.jpg   \n806  3464708890_3cab754998.jpg   \n807  2695085632_10c4e6ea78.jpg   \n808  2588456052_8842b47005.jpg   \n809  3436313241_6c73153fb6.jpg   \n\n                                                  text  \n0    A large wild cat is pursuing a horse across a ...  \n1           Two brown dogs fight on the leafy ground .  \n2    A man in shorts is standing on a rock looking ...  \n3        a muzzled white dog is running on the grass .  \n4                           A person skiing downhill .  \n..                                                 ...  \n805  A black dog carrying an object out of the water .  \n806  The man in the black hat is jumping over a cha...  \n807  A man whose clothes are covered in paint is wr...  \n808  A woman in a purple tank top holds a tennis ra...  \n809  A small black dog playing with a ball in the g...  \n\n[810 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2973269132_252bfd0160.jpg</td>\n      <td>A large wild cat is pursuing a horse across a ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>270263570_3160f360d3.jpg</td>\n      <td>Two brown dogs fight on the leafy ground .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2053006423_6adf69ca67.jpg</td>\n      <td>A man in shorts is standing on a rock looking ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>512101751_05a6d93e19.jpg</td>\n      <td>a muzzled white dog is running on the grass .</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3156406419_38fbd52007.jpg</td>\n      <td>A person skiing downhill .</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>805</th>\n      <td>1392272228_cf104086e6.jpg</td>\n      <td>A black dog carrying an object out of the water .</td>\n    </tr>\n    <tr>\n      <th>806</th>\n      <td>3464708890_3cab754998.jpg</td>\n      <td>The man in the black hat is jumping over a cha...</td>\n    </tr>\n    <tr>\n      <th>807</th>\n      <td>2695085632_10c4e6ea78.jpg</td>\n      <td>A man whose clothes are covered in paint is wr...</td>\n    </tr>\n    <tr>\n      <th>808</th>\n      <td>2588456052_8842b47005.jpg</td>\n      <td>A woman in a purple tank top holds a tennis ra...</td>\n    </tr>\n    <tr>\n      <th>809</th>\n      <td>3436313241_6c73153fb6.jpg</td>\n      <td>A small black dog playing with a ball in the g...</td>\n    </tr>\n  </tbody>\n</table>\n<p>810 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Define the DataModule**","metadata":{}},{"cell_type":"code","source":"class ImageCaptioningDataset(Dataset):\n    def __init__(self, image_path, captions, processor):\n        self.image_path=image_path\n        self.caption=caption\n        self.processor=processor\n    def __len__(self):\n        return len(self.image_path)\n    def __getitem__(self, idx):\n        image = Image.open(self,image_paths[idx]).convert(\"RGB\")\n        caption = self.caption[idx]\n        inputs = self.processor(images.image,\n                                text=caption,\n                                return_tensors=\"pt\",\n                                padding=\"max_length\",\n                                truncation=True)\n        inputs = {key: val.squeeze() for key, val in inputs.items()}\n        inputs['labels'] = inputs['input_ids'].clone()\n        return inputs\n\nclass ImageCaptioningDataModule(pl.LightningDataModule):\n    def __init__(self, train_df, val_df, processor, batch_size=8):\n        super().__init__()\n        self.train_df = train_df\n        self.val_df = val_df\n        self.processor = processor\n        self.batch_size = batch_size\n        \n    def setup(self, stage=None):\n        self.train_df = ImageCaptioningDataset(\n            image_paths = self.train_df['image_path'].tolist(),\n            captions = self.train_df['text'].tolist(),\n            processor = self.processor\n        )\n        self.val_df = ImageCaptioningDataset(\n            image_paths = self.val_df['image_path'].tolist(),\n            caption = self.val_dfval['image_path'].tolist(),\n            processor = self.processor\n        )\n        \n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_dataset, batch_size=self.batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:08:04.440648Z","iopub.execute_input":"2024-05-30T13:08:04.441284Z","iopub.status.idle":"2024-05-30T13:08:04.456119Z","shell.execute_reply.started":"2024-05-30T13:08:04.441251Z","shell.execute_reply":"2024-05-30T13:08:04.454508Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**Define the LightningModule**","metadata":{}},{"cell_type":"code","source":"class Blip2FineTuner(pl.LightningModule):\n    def __init__(self, model, processor, learning_rate=1e-5):\n        super().__init__()\n        self.model = model\n        self.processor = processor\n        self.learning_rate = learning_rate\n        \n    def forward(self, input_ids, attention_mask, pixel_values, labels=None):\n        outputs = model(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            pixel_values = pixel_values,\n            labels = labels\n        )\n        return output\n    \n    def validation_step(self, batch, batch_idx):\n        outputs = self(**batch)\n        loss = outputs.loss\n        self.log(\"val_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = AdamW(self.parameters(), lr=self.learning_rate)\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=0,\n            num_training_steps=self.trainer.estimated_stepping_batches\n        )\n        return [optimizer], [scheduler]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:08:05.410985Z","iopub.execute_input":"2024-05-30T13:08:05.411376Z","iopub.status.idle":"2024-05-30T13:08:05.422513Z","shell.execute_reply.started":"2024-05-30T13:08:05.411348Z","shell.execute_reply":"2024-05-30T13:08:05.421064Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Training Script","metadata":{}},{"cell_type":"code","source":"# Load model directly\nfrom transformers import AutoProcessor, AutoModelForVisualQuestionAnswering\nfrom lightning.pytorch.callbacks import ModelPruning\nfrom lightning.pytorch.loggers import WandbLogger\n\nwandb_logger = WandbLogger(project=\"Blip2-FineTuned\", log_model=\"all\")\n\n\nprocessor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-6.7b-coco\")\nmodel = AutoModelForVisualQuestionAnswering.from_pretrained(\"Salesforce/blip2-opt-6.7b-coco\")\n\ndata_module = ImageCaptioningDataModule(train_df, val_df, processor, batch_size=8)\nmodel_module = Blip2FineTuner(model, processor, learning_rate=1e-5)\n\n\n\ntrainer = pl.Trainer(\n    max_epochs=3, min_steps=None,\n    devices=1, accelerator=\"auto\", strategy=\"ddp\",\n    precision=\"16-mixed\",  # Use mixed precision training\n    callbacks=[ModelPruning(\"l1_unstructured\", amount=0.5),monitor=\"val_loss\"],\n\n    enable_progress_bar=True,\n    check_val_every_n_epoch=1,\n    profiler=\"simple\",\n    logger=wandb_logger,\n#     fast_dev_run=5, #For testing\n)\n    \n    \ntrainer.fit(model_module, data_module)\nwandb_logger.watch(model)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# filepath = \"Blip2_fine-tuned.onnx\"\n# model.to_onnx(filepath, input_sample, export_params=True)\n","metadata":{},"execution_count":null,"outputs":[]}]}