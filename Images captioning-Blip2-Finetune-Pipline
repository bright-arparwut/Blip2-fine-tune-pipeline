{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1111676,"sourceType":"datasetVersion","datasetId":623289}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade --q transformers lightning datasets bitsandbytes gspread oauth2client wandb peft trl","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:36:53.673834Z","iopub.execute_input":"2024-06-08T14:36:53.674396Z","iopub.status.idle":"2024-06-08T14:37:35.767562Z","shell.execute_reply.started":"2024-06-08T14:36:53.674360Z","shell.execute_reply":"2024-06-08T14:37:35.766612Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.6 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-pubsub 2.19.0 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport lightning as pl\n\nimport transformers\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BitsAndBytesConfig\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:37:35.769403Z","iopub.execute_input":"2024-06-08T14:37:35.769697Z","iopub.status.idle":"2024-06-08T14:37:43.710794Z","shell.execute_reply.started":"2024-06-08T14:37:35.769671Z","shell.execute_reply":"2024-06-08T14:37:43.709990Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data Prep\n* Prep data.csv\n* Define the DataModule\n* Define the LightningModule\n","metadata":{}},{"cell_type":"code","source":"PATH_DIR = \"/kaggle/input/flickr8k\"\nIMAGE_FOLDER_DIR = \"/kaggle/input/flickr8k/Images\"","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:37:43.711931Z","iopub.execute_input":"2024-06-08T14:37:43.712389Z","iopub.status.idle":"2024-06-08T14:37:43.716646Z","shell.execute_reply.started":"2024-06-08T14:37:43.712361Z","shell.execute_reply":"2024-06-08T14:37:43.715641Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/flickr8k/captions.txt')\ndata.rename(columns={\"image\":\"image_path\",\"caption\":\"text\"},inplace=True)\ndata","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:37:43.719079Z","iopub.execute_input":"2024-06-08T14:37:43.719405Z","iopub.status.idle":"2024-06-08T14:37:43.863275Z","shell.execute_reply.started":"2024-06-08T14:37:43.719369Z","shell.execute_reply":"2024-06-08T14:37:43.862294Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                      image_path  \\\n0      1000268201_693b08cb0e.jpg   \n1      1000268201_693b08cb0e.jpg   \n2      1000268201_693b08cb0e.jpg   \n3      1000268201_693b08cb0e.jpg   \n4      1000268201_693b08cb0e.jpg   \n...                          ...   \n40450   997722733_0cb5439472.jpg   \n40451   997722733_0cb5439472.jpg   \n40452   997722733_0cb5439472.jpg   \n40453   997722733_0cb5439472.jpg   \n40454   997722733_0cb5439472.jpg   \n\n                                                    text  \n0      A child in a pink dress is climbing up a set o...  \n1                  A girl going into a wooden building .  \n2       A little girl climbing into a wooden playhouse .  \n3      A little girl climbing the stairs to her playh...  \n4      A little girl in a pink dress going into a woo...  \n...                                                  ...  \n40450           A man in a pink shirt climbs a rock face  \n40451           A man is rock climbing high in the air .  \n40452  A person in a red shirt climbing up a rock fac...  \n40453                    A rock climber in a red shirt .  \n40454  A rock climber practices on a rock climbing wa...  \n\n[40455 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A child in a pink dress is climbing up a set o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A girl going into a wooden building .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing into a wooden playhouse .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl climbing the stairs to her playh...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000268201_693b08cb0e.jpg</td>\n      <td>A little girl in a pink dress going into a woo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>40450</th>\n      <td>997722733_0cb5439472.jpg</td>\n      <td>A man in a pink shirt climbs a rock face</td>\n    </tr>\n    <tr>\n      <th>40451</th>\n      <td>997722733_0cb5439472.jpg</td>\n      <td>A man is rock climbing high in the air .</td>\n    </tr>\n    <tr>\n      <th>40452</th>\n      <td>997722733_0cb5439472.jpg</td>\n      <td>A person in a red shirt climbing up a rock fac...</td>\n    </tr>\n    <tr>\n      <th>40453</th>\n      <td>997722733_0cb5439472.jpg</td>\n      <td>A rock climber in a red shirt .</td>\n    </tr>\n    <tr>\n      <th>40454</th>\n      <td>997722733_0cb5439472.jpg</td>\n      <td>A rock climber practices on a rock climbing wa...</td>\n    </tr>\n  </tbody>\n</table>\n<p>40455 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df, val_df = train_test_split(data,\n                                   test_size=.02,\n                                   shuffle=True,\n                                   random_state=42,)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:37:43.864615Z","iopub.execute_input":"2024-06-08T14:37:43.864937Z","iopub.status.idle":"2024-06-08T14:37:43.877947Z","shell.execute_reply.started":"2024-06-08T14:37:43.864911Z","shell.execute_reply":"2024-06-08T14:37:43.877101Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df.reset_index(inplace=True,\n                     drop=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:37:43.879227Z","iopub.execute_input":"2024-06-08T14:37:43.879632Z","iopub.status.idle":"2024-06-08T14:37:43.891274Z","shell.execute_reply.started":"2024-06-08T14:37:43.879603Z","shell.execute_reply":"2024-06-08T14:37:43.890291Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                      image_path  \\\n0      3630641436_8f9ac5b9b2.jpg   \n1      3494394662_3edfd4a34c.jpg   \n2      3435648640_b2f68efb78.jpg   \n3      2847615962_c330bded6e.jpg   \n4       439916996_1ddb9dc8e7.jpg   \n...                          ...   \n39640  2220175999_081aa9cce8.jpg   \n39641  2555622234_3e531e4014.jpg   \n39642   525887861_4cc7a1beca.jpg   \n39643  1204996216_71d7519d9a.jpg   \n39644  2862931640_2501bd36c5.jpg   \n\n                                                    text  \n0      Three dogs rush to chase a ball thrown into th...  \n1      A man with a red collar and gray beard looks a...  \n2      A black dog and a brindle dog wrestle in the d...  \n3      A spotted dog rolling over on a pad placed on ...  \n4      A brown dog persues a Frisbee across the grass...  \n...                                                  ...  \n39640                     Two big dogs wade in the ocean  \n39641  A wet German Shepherd runs along the waves on ...  \n39642                   Little girl in pink skateboard .  \n39643               A boy lays on a picnic table bench .  \n39644  A group of young people pose for a group photo...  \n\n[39645 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3630641436_8f9ac5b9b2.jpg</td>\n      <td>Three dogs rush to chase a ball thrown into th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3494394662_3edfd4a34c.jpg</td>\n      <td>A man with a red collar and gray beard looks a...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3435648640_b2f68efb78.jpg</td>\n      <td>A black dog and a brindle dog wrestle in the d...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2847615962_c330bded6e.jpg</td>\n      <td>A spotted dog rolling over on a pad placed on ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>439916996_1ddb9dc8e7.jpg</td>\n      <td>A brown dog persues a Frisbee across the grass...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39640</th>\n      <td>2220175999_081aa9cce8.jpg</td>\n      <td>Two big dogs wade in the ocean</td>\n    </tr>\n    <tr>\n      <th>39641</th>\n      <td>2555622234_3e531e4014.jpg</td>\n      <td>A wet German Shepherd runs along the waves on ...</td>\n    </tr>\n    <tr>\n      <th>39642</th>\n      <td>525887861_4cc7a1beca.jpg</td>\n      <td>Little girl in pink skateboard .</td>\n    </tr>\n    <tr>\n      <th>39643</th>\n      <td>1204996216_71d7519d9a.jpg</td>\n      <td>A boy lays on a picnic table bench .</td>\n    </tr>\n    <tr>\n      <th>39644</th>\n      <td>2862931640_2501bd36c5.jpg</td>\n      <td>A group of young people pose for a group photo...</td>\n    </tr>\n  </tbody>\n</table>\n<p>39645 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"val_df.reset_index(inplace=True,\n                   drop=True)\nval_df","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:37:43.892667Z","iopub.execute_input":"2024-06-08T14:37:43.893047Z","iopub.status.idle":"2024-06-08T14:37:43.907557Z","shell.execute_reply.started":"2024-06-08T14:37:43.893016Z","shell.execute_reply":"2024-06-08T14:37:43.906457Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                    image_path  \\\n0    2973269132_252bfd0160.jpg   \n1     270263570_3160f360d3.jpg   \n2    2053006423_6adf69ca67.jpg   \n3     512101751_05a6d93e19.jpg   \n4    3156406419_38fbd52007.jpg   \n..                         ...   \n805  1392272228_cf104086e6.jpg   \n806  3464708890_3cab754998.jpg   \n807  2695085632_10c4e6ea78.jpg   \n808  2588456052_8842b47005.jpg   \n809  3436313241_6c73153fb6.jpg   \n\n                                                  text  \n0    A large wild cat is pursuing a horse across a ...  \n1           Two brown dogs fight on the leafy ground .  \n2    A man in shorts is standing on a rock looking ...  \n3        a muzzled white dog is running on the grass .  \n4                           A person skiing downhill .  \n..                                                 ...  \n805  A black dog carrying an object out of the water .  \n806  The man in the black hat is jumping over a cha...  \n807  A man whose clothes are covered in paint is wr...  \n808  A woman in a purple tank top holds a tennis ra...  \n809  A small black dog playing with a ball in the g...  \n\n[810 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2973269132_252bfd0160.jpg</td>\n      <td>A large wild cat is pursuing a horse across a ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>270263570_3160f360d3.jpg</td>\n      <td>Two brown dogs fight on the leafy ground .</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2053006423_6adf69ca67.jpg</td>\n      <td>A man in shorts is standing on a rock looking ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>512101751_05a6d93e19.jpg</td>\n      <td>a muzzled white dog is running on the grass .</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3156406419_38fbd52007.jpg</td>\n      <td>A person skiing downhill .</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>805</th>\n      <td>1392272228_cf104086e6.jpg</td>\n      <td>A black dog carrying an object out of the water .</td>\n    </tr>\n    <tr>\n      <th>806</th>\n      <td>3464708890_3cab754998.jpg</td>\n      <td>The man in the black hat is jumping over a cha...</td>\n    </tr>\n    <tr>\n      <th>807</th>\n      <td>2695085632_10c4e6ea78.jpg</td>\n      <td>A man whose clothes are covered in paint is wr...</td>\n    </tr>\n    <tr>\n      <th>808</th>\n      <td>2588456052_8842b47005.jpg</td>\n      <td>A woman in a purple tank top holds a tennis ra...</td>\n    </tr>\n    <tr>\n      <th>809</th>\n      <td>3436313241_6c73153fb6.jpg</td>\n      <td>A small black dog playing with a ball in the g...</td>\n    </tr>\n  </tbody>\n</table>\n<p>810 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Define the DataModule**","metadata":{}},{"cell_type":"code","source":"class ImageCaptioningDataset(Dataset):\n    def __init__(self, image_path, captions, processor):\n        self.image_path=image_path\n        self.caption=caption\n        self.processor=processor\n    def __len__(self):\n        return len(self.image_path)\n    def __getitem__(self, idx):\n        image = Image.open(self,image_paths[idx]).convert(\"RGB\")\n        caption = self.caption[idx]\n        inputs = self.processor(images.image,\n                                text=caption,\n                                padding=\"max_length\",\n                                truncation=True)\n        inputs = {key: val.squeeze() for key, val in inputs.items()}\n        inputs['labels'] = inputs['input_ids'].clone()\n        return inputs\n\nclass ImageCaptioningDataModule(pl.LightningDataModule):\n    def __init__(self, train_df, val_df, processor, batch_size=8):\n        super().__init__()\n        self.train_df = train_df\n        self.val_df = val_df\n        self.processor = processor\n        self.batch_size = batch_size\n        \n    def setup(self, stage=None):\n        self.train_df = ImageCaptioningDataset(\n            image_paths = self.train_df['image_path'].tolist(),\n            captions = self.train_df['text'].tolist(),\n            processor = self.processor\n        )\n        self.val_df = ImageCaptioningDataset(\n            image_paths = self.val_df['image_path'].tolist(),\n            caption = self.val_dfval['image_path'].tolist(),\n            processor = self.processor\n        )\n        \n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_dataset, batch_size=self.batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:37:43.908781Z","iopub.execute_input":"2024-06-08T14:37:43.909642Z","iopub.status.idle":"2024-06-08T14:37:43.921925Z","shell.execute_reply.started":"2024-06-08T14:37:43.909615Z","shell.execute_reply":"2024-06-08T14:37:43.921016Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Define the LightningModule**","metadata":{}},{"cell_type":"code","source":"class Blip2FineTuner(pl.LightningModule):\n    def __init__(self, model, processor, learning_rate=1e-5):\n        super().__init__()\n        self.model = model\n        self.processor = processor\n        self.learning_rate = learning_rate\n        \n    def forward(self, input_ids, attention_mask, pixel_values, labels=None):\n        outputs = model(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            pixel_values = pixel_values,\n            labels = labels\n        )\n        return output\n    \n    def validation_step(self, batch, batch_idx):\n        outputs = self(**batch)\n        loss = outputs.loss\n        self.log(\"val_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = AdamW(self.parameters(), lr=self.learning_rate)\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=0,\n            num_training_steps=self.trainer.estimated_stepping_batches\n        )\n        return [optimizer], [scheduler]","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:37:43.923125Z","iopub.execute_input":"2024-06-08T14:37:43.923422Z","iopub.status.idle":"2024-06-08T14:37:43.938274Z","shell.execute_reply.started":"2024-06-08T14:37:43.923397Z","shell.execute_reply":"2024-06-08T14:37:43.937429Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Training Script","metadata":{}},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True, \n    bnb_4bit_use_double_quant=True, \n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_quant_storage=torch.bfloat16,\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processor = AutoProcessor.from_pretrained(\"Salesforce/blip2-opt-6.7b-coco\")\nmodel = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-6.7b-coco\",\n                                                        quantization_config=bnb_config,\n                                                        device_map='cuda',\n                                                        torch_dtype=torch.bfloat16\n                                                    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_module = ImageCaptioningDataModule(train_df, val_df, processor, batch_size=8)\nmodel_module = Blip2FineTuner(model, processor, learning_rate=1e-5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoProcessor, AutoModelForVisualQuestionAnswering\nfrom lightning.pytorch.callbacks import ModelPruning\nfrom lightning.pytorch.loggers import WandbLogger\n\nwandb_logger = WandbLogger(project=\"Blip2-FineTuned\", log_model=\"all\")\n\ntrainer = pl.Trainer(\n    max_epochs=3, min_steps=None,\n    devices=2, accelerator=\"auto\", strategy=\"ddp\",\n    precision=\"16-mixed\",  # Use mixed precision training\n    callbacks=[ModelPruning(\"l1_unstructured\", amount=0.5),monitor:=\"val_loss\"],\n\n    enable_progress_bar=True,\n    check_val_every_n_epoch=1,\n    profiler=\"simple\",\n    logger=wandb_logger,\n    fast_dev_run=5, #For testing\n)\n    \n    \ntrainer.fit(model_module, data_module)\nwandb_logger.watch(model)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-08T14:58:07.280573Z","iopub.execute_input":"2024-06-08T14:58:07.280997Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"2024-06-08 14:58:14.869406: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-08 14:58:14.869507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-08 14:58:15.035768: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b215f95e64c449a4907035d520deec96"}},"metadata":{}}]},{"cell_type":"code","source":"\n# filepath = \"Blip2_fine-tuned.onnx\"\n# model.to_onnx(filepath, input_sample, export_params=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-30T14:28:40.280987Z","iopub.status.idle":"2024-05-30T14:28:40.281376Z","shell.execute_reply.started":"2024-05-30T14:28:40.281198Z","shell.execute_reply":"2024-05-30T14:28:40.281213Z"},"trusted":true},"execution_count":null,"outputs":[]}]}